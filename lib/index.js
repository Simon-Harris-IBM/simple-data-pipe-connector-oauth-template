//-------------------------------------------------------------------------------
// Copyright IBM Corp. 2015
//
// Licensed under the Apache License, Version 2.0 (the 'License');
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an 'AS IS' BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//-------------------------------------------------------------------------------

'use strict';

var fs = require('fs');
var _ = require('lodash');
var path = require('path');
var util = require('util');

var pipesSDK = require('simple-data-pipe-sdk');
var connectorExt = pipesSDK.connectorExt;

var bluemixHelperConfig = require('bluemix-helper-config');
var global = bluemixHelperConfig.global;

// TODO: Specify the passport strategy module (http://passportjs.org/) and declare it as a dependency.
//       This example utilizes the Reddit passport strategy.
var dataSourcePassportStrategy = require('passport-reddit').Strategy; 

/**
 * Sample connector that stores a few JSON records in Cloudant
 * Build your own connector by following the TODO instructions
 */
function oAuthSampleConnector( parentDirPath ){

	 /* 
	  * Customization is mandatory
	  */

	// TODO: 
	//   Replace 'Stripe OAuth Data Source' with the desired display name of the data source (e.g. reddit) from which data will be loaded
	var connectorInfo = {
						  id: require('../package.json').simple_data_pipe.name,			// derive internal connector ID from package.json
						  name: 'Sample OAuth Data Source'								// TODO; change connector display name
						};

	// TODO: customize options						
	var connectorOptions = {
					  		recreateTargetDb: true, // if set (default: false) all data currently stored in the staging database is removed prior to data load
					  		useCustomTables: true   // keep true (default: false)
						   };						

	// Call constructor from super class; 
	connectorExt.call(this, 
					 connectorInfo.id, 			
					 connectorInfo.name, 
					 connectorOptions	  
					 );	

	// writes to the application's global log file
	var globalLog = this.globalLog;

	/**
	 * Customization is mandatory!
	 * Define the passport strategy to use for oAuth authentication with the data source
	 * @param pipe - data pipe configuration, containing the user-provided oAuth client id and client secret
	 * @returns a passport strategy for this data source
	 */
	this.getPassportStrategy = function(pipe) {

		return new dataSourcePassportStrategy({
			clientID: pipe.clientId,											 // mandatory; oAuth client id; do not change
	        clientSecret: pipe.clientSecret,									 // mandatory; oAuth client secret;do not change
	        callbackURL: global.getHostUrl() + '/authCallback',		 			 // mandatory; oAuth callback; do not change
	        customHeaders: { 'User-Agent': 'Simple Data Pipe demo application'}, // TODO define data source specific strategy options
	        scope: 'identity,read'												 // TODO define data source specific strategy options, such as scope		
		  },
		  function(accessToken, refreshToken, profile, done) {					 // Passport verify callback; customize signature as needed

			  process.nextTick(function () {

			  	// Mandatory; attach the obtained access token to the user profile
			  	// Mandatory, if applicable; also attach the obtained refresh token to the user profile
			  	// the user profile is passed as a parameter to authCallback()
		        profile.oauth_access_token = accessToken; 
		        
		        profile.oauth_refresh_token = refreshToken; 

			    return done(null, profile);
			  });
		  }
		);
	};

	/**
	 * Customization is mandatory!	
	 * Returns list of data source specific OAuth options to be passed to the passport.authenticate call,
	 * which starts the OAuth flow.
	 * @override
	 * @returns {scope:'read_only'} {@link https://github.com/reddit/reddit/wiki/OAuth2}
	 */
	this.getPassportAuthorizationParams = function() {
	   // no options required by default	
       return {};
	}; // getPassportAuthorizationParams

	/**
	 * Customization is mandatory!	
	 * passportAuthCallbackPostProcessing: post processing for OAuth authentication protocol
	 * Stores accessToken + refreshToken and retrieves list of available 'tables' (stripe objects) that can be moved by the pipe
	 * @param profile - the output generated by the passport verify callback
	 * @param pipe - data pipe configuration
	 * @param callback(err, pipe ) error information in case of a problem or the updated pipe
	 */
	this.passportAuthCallbackPostProcessing = function( profile, pipe, callback ){
				
        // TODO: attach the token(s) and other relevant information from the profile to the pipe configuration
        //       use this information in the connector code to access the data source

		pipe.oAuth = { 
						accessToken : profile.oauth_access_token, 
						refreshToken: profile.oauth_refresh_token 
					};

		// Fetch list of data sets that the user can choose from; the list is displayed in the Web UI in the "Filter Data" panel.
        // Attach data set list to the pipe configuration
		this.getSampleDataSetList(pipe, function (err, pipe){
			if(err) {
		    	globalLog.error('OAuth post processing failed. The sample data set list could not be created for data pipe configuration ' + pipe._id + ': ' + err);
		    }	
		    else {
			    globalLog.debug('OAuth post processing completed. Data pipe configuration was updated: ');
			    globalLog.debug(' ' + util.inspect(pipe,3));
		    }	

			return callback(err, pipe);
		});			

	}; // authCallback

	/*
	 * Customization is mandatory!
	 * @param {Object} pipe - Data pipe configuration
	 * @param {callback} done - invoke after processing is complete or has resulted in an error; parameters (err, updated_pipe_configuration)
	 * @return list of data sets (also referred to as tables for legacy reasons) from which the user can choose from
	 */
	this.getSampleDataSetList = function(pipe, done){

		var dataSets = [];

		// TODO: 'Define' the data set or data sets that can be loaded from the data source. The user gets to choose one.
		// dataSets.push({name:'dataSetName', label:'dataSetDisplayName'}); // assign the name to each property

		/* 
		 * In this example the data source contains several static data sets - transcripts of the victory speeches of 
		 * the Republican and Democratic 2016 presidential candidates.
		 */

	 	// set data set location
	 	var sampleDataDir = path.join(__dirname,'..','sample_data' + path.sep);

	 	// load data set metadata file
	 	var transciptListings;
	 	try {
				transciptListings = require(sampleDataDir + 'transcriptListings.json'); 		 		
	 	}
	 	catch(e) {
	 		// only triggered by a code logic or packaging error; return error
	 		globalLog.error('Sample data sets could not be loaded: ' + util.inspect(e,3));
	 		return done(util.inspect(e,3));
	 	}

	 	// retrieve listings and verify that a transcript file is available
 		var fileStat;
		_.forEach(transciptListings, 
		 		  function (listing) { 							 	
		 		  						// verify that the transcript file exists
										fileStat = fs.statSync(sampleDataDir + listing.transcript);
										if (fileStat && !fileStat.isDirectory()) {
											    dataSets.push(
											    				{
											    					name: listing.transcript_id, 
											    					label:listing.transcript_id
											    				});	    	
										 }
	 			  }
	 	);

		// Sometimes you might want to provide the user with the option to load all data sets concurrently
		// To enable that feature, define a single data set that contains only property 'labelPlural' 
		dataSets.push({labelPlural:'All victory speeches'});

		// In the UI the user gets to choose from: 
		//  -> All data sets
		//  -> sample data set 1
		//  -> ...

		// sort data set list (if present, the ALL_DATA option should be displayed first)
		// attach data set list to data pipe configuration document
		pipe.tables =  dataSets.sort(function (dataSet1, dataSet2) {
																		if(! dataSet1.name)	{ // ALL_DATA (only property labelPlural is defined)
																			return -1;
																		}

																		if(! dataSet2.name) {// ALL_DATA (only property labelPlural is defined)
																			return 1;
																		}

																		return dataSet1.label.localeCompare(dataSet2.label);
																   });

		return done(null, pipe);

	}; // getSampleDataSetList

   /*
	* ---------------------------------------------------------------------------------------
	* Override general connector methods:
	*  - doConnectStep: verify that OAuth information is still valid
	*  - fetchRecords:  load data from data source
	* ---------------------------------------------------------------------------------------
	*/

   /**
	* Customization is mandatory.
	* During data pipe runs, this method is invoked first. Add custom code as required, for example to verify that the 
	* OAuth token has not expired.
	* @param done(err) - callback funtion to be invoked after processing is complete
	* @param pipe - data pipe configuration
	* @param pipeRunLog - a dedicated logger instance that is only available during data pipe runs	
	*/
	this.doConnectStep = function( done, pipeRunStep, pipeRunStats, pipeRunLog, pipe, pipeRunner ){

		// do nothing by default
		return done();

	}; // doConnectStep

	
	/*
	 * Customization is mandatory!
	 * Implement the code logic to fetch data from the source, optionally enrich it and store it in Cloudant.
	 * @param dataSet - dataSet.name contains the data set name that was (directly or indirectly) selected by the user
	 * @param done(err) - callback funtion to be invoked after processing is complete
	 * @param pipe - data pipe configuration
	 * @param pipeRunLog - a dedicated logger instance that is only available during data pipe runs
	 */
	this.fetchRecords = function( dataSet, pushRecordFn, done, pipeRunStep, pipeRunStats, pipeRunLog, pipe, pipeRunner ){

		// The data set is typically selected by the user in the "Filter Data" panel during the pipe configuration step
		// dataSet: {name: 'data set name'}. However, if you enabled the ALL option (see get Tables) and it was selected, 
		// the fetchRecords function is invoked asynchronously once for each data set.

		// Bunyan logging - https://github.com/trentm/node-bunyan
		// The log file is attached to the pipe run document, which is stored in the Cloudant repository database named pipes_db.
		// To enable debug logging, set environment variable DEBUG to '*'' or 'to sdp-pipe-run' (withoiut the quotes).
		pipeRunLog.debug('Fetching data set ' + dataSet.name + ' from cloud data source.');

		// TODO: fetch data from cloud data source
		// in this sample the data source contains static data sets that are loaded from local files

		// set data set location
	 	var sampleDataDir = path.join(__dirname, '..', 'sample_data' + path.sep);


	 	// load listings and lookup metadata
		var transciptListings = require(sampleDataDir + 'transcriptListings.json'); 
		var listing = _.find(transciptListings, function(listing){
									return (dataSet.name === listing.transcript_id);
					  		});

		if(!listing) {
			// Invoke done callback function to terminate execution and pass an error message
			pipeRunLog.error('The data set cannot be found.');
			return done('The data set cannot be found.');
		}

		fs.readFile(sampleDataDir + listing.transcript, function(err, data) {
			if(err) {
				pipeRunLog.error('The data set could not be loaded: ' + err);
				// Invoke done callback function to terminate execution and pass an error message
				return done('The data set could not be loaded: ' + err);
			}

			var record = {
							winner: listing.winner,
							party: listing.party,
							location: listing.location,		
							transcript: data.toString()
						 };

			/* 
			   TODO: The results of a data pipe run are persisted in Cloudant by invoking pushRecordFn, passing a single record
			         {...} or multiple records [{...}].
			         One Cloudant database is created for each data set and named using the following algorithm:
			         getTablePrefix() + dataSet.name. 
			         The total number of records is automatically calculated if this function is invoked multiple times.
			*/

			// 
			// Parameter: pass a single record or a set of records to be persisted
			//             
			pushRecordFn(record);

			// Invoke done callback to indicate that data set dataSet has been processed. 
			// Parameters:
			//  done()                                      // no parameter; processing completed successfully. no status message text is displayed to the end user in the monitoring view
			//  done({infoStatus: 'informational message'}) // processing completed successfully. the value of the property infoStatus is displayed to the end user in the monitoring view
			//  done({errorStatus: 'error message'})        // a fatal error was encountered during processing. the value of the property infoStatus is displayed to the end user in the monitoring view
			//  done('error message')                       // deprecated; a fatal error was encountered during processing. the message is displayed to the end user in the monitoring view
			return done();	

		});
	}; // fetchRecords

	/*
	 * Customization is not needed.
	 */
	this.getTablePrefix = function(){
		// The prefix is used to generate names for the Cloudant staging databases that hold your data. The recommended
		// value is the connector ID to assure uniqueness.
		return connectorInfo.id;
	};


}



//Extend event Emitter
util.inherits(oAuthSampleConnector, connectorExt);

module.exports = new oAuthSampleConnector();